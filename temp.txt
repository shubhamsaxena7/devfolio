Introduction: The Systems Lens
Highlight (yellow) - Page 2
A system is a set of things— people, cells, molecules, or whatever— interconnected in such a way that they produce their own pattern of behavior over time.
Highlight (yellow) - Page 2
The system, to a large extent, causes its own behavior! An outside event may unleash that behavior, but the same outside event applied to a different system is likely to produce a different result.
Highlight (pink) - Page 3
Because of feedback delays within complex systems, by the time a problem becomes apparent it may be unnecessarily difficult to solve.
Highlight (yellow) - Page 5
Words and sentences must, by necessity, come only one at a time in linear, logical order. Systems happen all at once. They are connected not just in one direction, but in many directions simultaneously.
Highlight (yellow) - Page 5
the basic operating unit of a system: the feedback loop.
Highlight (yellow) - Page 7
The behavior of a system cannot be known just by knowing the elements of which the system is made.
  Part One: System Structure and Behavior
Highlight (yellow) - One: The Basics > Page 11
A system* is an interconnected set of elements that is coherently organized in a way that achieves something.
Highlight (yellow) - One: The Basics > Page 11
a system must consist of three kinds of things: elements, interconnections, and a function or purpose.
Highlight (yellow) - One: The Basics > Page 12
A system is more than the sum of its parts. It may
Highlight (yellow) - One: The Basics > Page 12
exhibit adaptive, dynamic, goal- seeking, self- preserving, and sometimes evolutionary behavior.
Highlight (yellow) - One: The Basics > Page 12
there is an integrity or wholeness about a system and an active set of mechanisms to maintain that integrity.
Highlight (yellow) - One: The Basics > Page 12
Systems can be self- organizing, and often are self- repairing over at least some range of disruptions. They are resilient, and many of them are evolutionary.
Highlight (yellow) - One: The Basics > Page 13
Can you identify parts?… and B) Do the parts affect each other?… and C) Do the parts together produce an effect that is different from the effect of each part on its own?… and perhaps D) Does the effect, the behavior over time, persist in a variety of circumstances?
  Highlight (yellow) - One: The Basics > Page 14
It’s easier to learn about a system’s elements than about its interconnections.
Highlight (yellow) - One: The Basics > Page 14
Many of the interconnections in systems operate through the flow of information. Information holds systems together and plays
Highlight (yellow) - One: The Basics > Page 14
a great role in determining how they operate.
Highlight (yellow) - One: The Basics > Page 14
Many interconnections are flows of information— signals that go to decision points or action points within a system. These kinds of interconnections are often harder to see,
Highlight (yellow) - One: The Basics > Page 14
The best way to deduce the system’s purpose is to watch for a while to see how the system behaves.
Highlight (yellow) - One: The Basics > Page 14
Purposes are deduced from behavior, not from rhetoric or stated goals.
Highlight (yellow) - One: The Basics > Page 15
Systems can be nested within systems. Therefore, there can be purposes within purposes.
Highlight (yellow) - One: The Basics > Page 16
Keeping sub- purposes and overall system purposes in harmony is an essential function of successful systems.
Highlight (yellow) - One: The Basics > Page 16
Changing elements usually has the least effect on the system.
Highlight (yellow) - One: The Basics > Page 16
If you change all the players on a football team, it is still recognizably a football team.
Highlight (yellow) - One: The Basics > Page 17
A stock is the foundation of any system. Stocks are the elements of the system that you can see, feel, count, or measure at any given time.
Highlight (yellow) - One: The Basics > Page 17
A system stock is just what it sounds like: a store, a quantity, an accumulation of material or information that has built up over time.
Highlight (yellow) - One: The Basics > Page 18
A stock is the memory of the history of changing flows within the system.
Highlight (yellow) - One: The Basics > Page 18
Stocks change over time through the actions of a flow.
Highlight (yellow) - One: The Basics > Page 18
A stock, then, is the present memory of the history of changing flows within the system.
Highlight (yellow) - One: The Basics > Page 23
A stock takes time to change, because flows take time to flow.
Highlight (yellow) - One: The Basics > Page 23
Stocks generally change slowly, even when the flows into or out of them change suddenly. Therefore, stocks act as delays or buffers or shock absorbers in systems.
Highlight (yellow) - One: The Basics > Page 23
The time lags imposed by stocks allow room to maneuver, to experiment, and to revise policies that aren’t working.
Highlight (yellow) - One: The Basics > Page 24
Stocks allow inflows and outflows to be decoupled and to be independent and temporarily out of balance with each other.
Highlight (yellow) - One: The Basics > Page 25
Systems thinkers see the world as a collection of stocks along with the mechanisms for regulating the levels in the stocks by manipulating flows.
Highlight (yellow) - One: The Basics > Page 25
How the System Runs Itself— Feedback
Highlight (yellow) - One: The Basics > Page 25
A feedback loop is formed when changes in a stock affect the flows into or out of that same stock.
Highlight (yellow) - One: The Basics > Page 28
Balancing feedback loops are goal- seeking or stability-
Highlight (yellow) - One: The Basics > Page 31
A reinforcing feedback loop enhances whatever direction of change is imposed on it.
Highlight (yellow) - One: The Basics > Page 31
Reinforcing loops are found wherever a system element has the ability to reproduce itself or to grow as a constant fraction of itself. Those elements include populations and economies.
Highlight (yellow) - One: The Basics > Page 32
Reinforcing feedback loops are self- enhancing, leading to exponential growth or to runaway collapses over time. They are found whenever a stock has the capacity to reinforce or reproduce itself.
Highlight (yellow) - One: The Basics > Page 34
If A causes B, is it possible that B also causes A?
  Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 39
The information delivered by a feedback loop can only affect future behavior; it can’t deliver the information, and so can’t have an impact fast enough to correct behavior that drove the current feedback.
Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 40
your mental model of the system needs to include all the important flows, or you will be surprised by the system’s behavior.
Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 40
A stock- maintaining balancing feedback loop must have its goal set appropriately to compensate for draining or inflowing processes that affect that stock. Otherwise, the feedback process will fall short of or exceed the target for the stock.
Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 51
Systems with similar feedback structures produce similar dynamic behaviors.
Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 58
Economies are extremely complex systems; they are full of balancing feedback loops with delays, and they are inherently oscillatory. 5
Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 59
any physical, growing system is going to run into some kind of constraint, sooner or later. That constraint will take the form of a balancing loop that in some way shifts the dominance of the reinforcing loop driving the growth behavior, either by strengthening the outflow or by weakening the inflow.
Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 59
In physical, exponentially growing systems, there must be at least one reinforcing loop driving the growth and at least one balancing loop constraining the growth, because no physical system can grow forever in a finite environment.
Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 71
Nonrenewable resources are stock- limited. The entire
Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 71
stock is available at once, and can be extracted at any rate (limited mainly by extraction capital). But since the stock is not renewed, the faster the extraction rate, the shorter the lifetime of the resource.
Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 71
Renewable resources are flow- limited. They can support extraction or harvest indefinitely, but only at a finite flow rate equal to their regeneration rate. If they are extracted faster than they regenerate, they may eventually be driven below a critical threshold and become, for all practical purposes, nonrenewable.
Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 72
If the feedback is fast enough to stop capital growth before the critical threshold is reached, the whole system comes smoothly into equilibrium. If the balancing feedback is slower and less effective, the system oscillates. If the balancing loop is very weak, so that capital can go on growing even as the resource is reduced below its threshold ability to regenerate itself, the resource and the industry both collapse.
Highlight (yellow) - Two: A Brief Visit to the Systems Zoo > Page 72
The trick, as with all the behavioral possibilities of complex systems, is to recognize what structures contain which latent behaviors, and what conditions release those behaviors— and, where possible, to arrange the structures and conditions to reduce the probability of destructive behaviors and to encourage the possibility of beneficial ones.
  Part Two: Systems and Us
Highlight (yellow) - Three: Why Systems Work So Well > Page 76
Resilience is a measure of a system’s ability to survive and persist within a variable environment. The opposite of resilience is brittleness or rigidity.
Highlight (yellow) - Three: Why Systems Work So Well > Page 76
Resilience arises from a rich structure of many feedback loops that can work in different ways to restore a system even after a large perturbation.
Highlight (yellow) - Three: Why Systems Work So Well > Page 76
A set of feedback loops that can restore or rebuild feedback loops is resilience at a still higher level— meta- resilience,
Highlight (yellow) - Three: Why Systems Work So Well > Page 76
Even higher meta- meta- resilience comes from feedback loops that can learn, create, design, and evolve ever more complex restorative structures. Systems that can do this are self- organizing,
Highlight (yellow) - Three: Why Systems Work So Well > Page 77
Short- term oscillations, or periodic outbreaks, or long cycles of succession, climax, and collapse may in fact be the normal condition, which resilience acts to restore!
Highlight (yellow) - Three: Why Systems Work So Well > Page 77
systems that are constant over time can be unresilient.
Highlight (yellow) - Three: Why Systems Work So Well > Page 78
think of resilience as a plateau upon which the system can play, performing its normal functions in safety. A resilient system has a big plateau, a lot of space over which it can wander, with gentle, elastic walls that will bounce it back, if it comes near a dangerous edge. As a system loses its resilience, its plateau shrinks, and its protective walls become lower and more rigid, until the system is operating on a knife- edge,
Highlight (yellow) - Three: Why Systems Work So Well > Page 78
Systems need to be managed not only for productivity or stability, they also need to be managed for resilience— the ability to recover from perturbation, the ability to restore or repair themselves.
Highlight (yellow) - Three: Why Systems Work So Well > Page 79
This capacity of a system to make its own structure more complex is called self- organization.
Highlight (yellow) - Three: Why Systems Work So Well > Page 79
Self- organization produces heterogeneity and unpredictability. It is likely to come up with whole new structures, whole new ways of doing things. It requires freedom and experimentation,
Highlight (yellow) - Three: Why Systems Work So Well > Page 80
conditions that encourage self- organization often can be scary for individuals and threatening to power structures. As a consequence, education systems may restrict the creative powers of children instead of stimulating those powers.
Highlight (yellow) - Three: Why Systems Work So Well > Page 82
In the process of creating new structures and increasing complexity, one thing that a self- organizing system often generates is hierarchy.
Highlight (yellow) - Three: Why Systems Work So Well > Page 83
Complex systems can evolve from simple systems only if there are stable intermediate forms.
Highlight (yellow) - Three: Why Systems Work So Well > Page 83
The resulting complex forms will naturally be hierarchic. That may explain why hierarchies are so common in the systems nature presents to us. Among all possible complex forms, hierarchies are the only ones that have had the time to evolve. 5
Highlight (yellow) - Three: Why Systems Work So Well > Page 83
In hierarchical systems relationships within each subsystem are denser and stronger than relationships between subsystems. Everything is still connected to everything else, but not equally strongly.
Highlight (yellow) - Three: Why Systems Work So Well > Page 84
Early farmers decided to come together and form cities for self- protection and for making trade more efficient.
Highlight (yellow) - Three: Why Systems Work So Well > Page 84
The original purpose of a hierarchy is always to help its originating subsystems do their jobs better.
Highlight (yellow) - Three: Why Systems Work So Well > Page 85
When a subsystem’s goals dominate at the expense of the total system’s goals, the resulting behavior is called suboptimization.
Highlight (yellow) - Three: Why Systems Work So Well > Page 85
To be a highly functional system, hierarchy must balance the welfare, freedoms, and responsibilities of the subsystems and total system— there must be enough central control to achieve coordination toward the large- system goal, and enough autonomy to keep all subsystems flourishing, functioning, and self- organizing.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 86
Everything we think we know about the world is a model. Every word and every language is a model. All maps and statistics, books and databases, equations and computer programs are models. So are the ways I picture the world in my head— my mental models. None of these is or ever will be the real world.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 86
our models fall far short of representing the world fully. That is why we make mistakes and why we are regularly surprised.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 88
It’s endlessly engrossing to take in the world as a series of events, and constantly surprising, because that way of seeing the world has almost no predictive or explanatory value.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 89
The structure of a system is its interlocking stocks, flows, and feedback loops.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 89
Structure determines what behaviors are latent in the system. A goal- seeking balancing feedback loop approaches or holds a dynamic equilibrium. A reinforcing feedback loop generates exponential growth. The two of them linked together are capable of growth, decay, or equilibrium. If they also contain delays, they may produce oscillations.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 89
System structure is the source of system behavior.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 89
Systems thinking goes back and forth constantly between structure (diagrams of stocks, flows, and feedback) and behavior (time graphs).
Highlight (yellow) - Four: Why Systems Surprise Us > Page 90
behavior- based models are more useful than event- based ones, but they still have fundamental problems. First, they typically overemphasize system flows and underemphasize stocks. Economists follow the behavior of flows, because that’s where the interesting variations and most rapid changes in systems show up.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 90
We are too fascinated by the events they generate. We pay too little attention to their history. And we are insufficiently skilled at seeing in their history clues to the structures from which behavior and events flow.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 95
systems rarely have real boundaries.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 95
There are only boundaries of word, thought, perception, and social agreement— artificial, mental- model boundaries.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 97
When you draw boundaries too narrowly, the system surprises you. For example, if you try to deal with urban traffic problems without thinking about settlement patterns, you build highways, which attract housing developments along their whole length. Those households, in turn, put more cars on the highways, which then become just as clogged as before.
  Highlight (yellow) - Four: Why Systems Surprise Us > Page 97
There are no separate systems. The world is a continuum. Where to draw a boundary around a system depends on the purpose of the discussion— the questions we want to ask.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 98
We get attached to the boundaries our minds happen to be accustomed to.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 99
boundaries are of our own making, and that they can and should be reconsidered for each new discussion, problem, or purpose.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 101
Economics evolved in a time when labor and capital were the most common limiting factors to production
Highlight (yellow) - Four: Why Systems Surprise Us > Page 102
growth itself depletes or enhances limits and
Highlight (yellow) - Four: Why Systems Surprise Us > Page 102
therefore changes what is limiting.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 102
To shift attention from the abundant factors to the next potential limiting factor is to gain real understanding of, and control over, the growth process
Highlight (yellow) - Four: Why Systems Surprise Us > Page 102
For any physical entity in a finite environment, perpetual growth is impossible. Ultimately, the choice is not to grow forever but to decide what limits to live within.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 104
Just as the appropriate boundaries to draw around one’s picture of a system depend on the purpose of the discussion, so do the important delays
Highlight (yellow) - Four: Why Systems Surprise Us > Page 105
Delays determine how fast systems can react, how accurately they hit their targets, and how timely is the information passed around a system
Highlight (yellow) - Four: Why Systems Surprise Us > Page 105
When there are long delays in feedback loops, some sort of foresight is essential. To act only when a problem becomes obvious is to miss an important opportunity to solve the problem.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 106
Bounded rationality means that people make quite reasonable decisions based on the information they have. But they don’t have perfect information, especially about more distant parts of the system
Highlight (yellow) - Four: Why Systems Surprise Us > Page 106
We do our best to further our own nearby interests in a rational way, but we can take into account only what we know
Highlight (yellow) - Four: Why Systems Surprise Us > Page 106
We often don’t foresee (or choose to ignore) the impacts of our actions on the whole system. So instead of finding a long-term optimum, we discover within our limited purview a choice we can live with for now, and we stick to it, changing our behavior only when forced to.
  Bookmark - Four: Why Systems Surprise Us > Page 108
Highlight (yellow) - Four: Why Systems Surprise Us > Page 108
Change comes first from stepping outside the limited information that can be seen from any single place in the system and getting an overview
Highlight (yellow) - Four: Why Systems Surprise Us > Page 110
The bounded rationality of each actor in a system may not lead to decisions that further the welfare of the system as a whole.
Highlight (yellow) - Four: Why Systems Surprise Us > Page 110
What makes a difference is redesigning the system to improve the information, incentives, disincentives, goals, stresses, and constraints that have an effect on specific actors.
Highlight (yellow) - Five: System Traps … and Opportunities > Page 113
Policy resistance comes from the bounded rationalities of the actors in a system, each with his or her (or “its” in the case of an institution) own goals.
Highlight (yellow) - Five: System Traps … and Opportunities > Page 113
Each actor monitors the state of the system with regard to some important variable—income or prices or housing or drugs or investment—and compares that state with his, her, or its goal. If there is a discrepancy, each actor does something to correct the situation.
Highlight (yellow) - Five: System Traps … and Opportunities > Page 115
The most effective way of dealing with policy resistance is to find a way of aligning the various goals of the subsystems, usually by providing an overarching goal that allows all actors to break out of their bounded rationality
Highlight (yellow) - Five: System Traps … and Opportunities > Page 115
Harmonization of goals in a system is not always possible, but it’s an option worth looking for. It can be found only by letting go of more narrow goals and considering the long-term welfare of the entire system.
Highlight (yellow) - Five: System Traps … and Opportunities > Page 116
When various actors try to pull a system stock toward various goals, the result can be policy resistance. Any new policy, especially if it’s effective, just pulls the stock farther from the goals of other actors and produces additional resistance, with a result that no one likes, but that everyone expends considerable effort in maintaining.
Highlight (yellow) - Five: System Traps … and Opportunities > Page 117
The tragedy of the commons arises from missing (or too long delayed) feedback from the resource to the growth of the users of that resource.
Highlight (yellow) - Five: System Traps … and Opportunities > Page 118
If you think that the reasoning of an exploiter of the commons is hard to understand, ask yourself how willing you are to carpool in order to reduce air pollution
Highlight (yellow) - Five: System Traps … and Opportunities > Page 119
The structure of a commons system makes selfish behavior much more convenient and profitable than behavior that is responsible to the whole community and to the future.
Highlight (yellow) - Five: System Traps … and Opportunities > Page 121
When there is a commonly shared resource, every user benefits directly from its use, but shares the costs of its abuse with everyone else. Therefore, there is very weak feedback from the condition of the resource to the decisions of the resource users. The consequence is overuse of the resource, eroding it until it becomes unavailable to anyone.
Highlight (yellow) - Five: System Traps … and Opportunities > Page 121
Educate and exhort the users, so they understand the consequences of abusing the resource. And also restore or strengthen the missing feedback link, either by privatizing the resource so each user feels the direct consequences of its abuse or (since many resources cannot be privatized) by regulating the access of all users to the resource.
  Part Three: Creating Change—in Systems and in Our Philosophy
Highlight (yellow) - Six: Leverage Points—Places to Intervene in a System > Page 146
Leverage points frequently are not intuitive. Or if they are, we too often use them backward, systematically worsening whatever problems we are trying to solve.
Highlight (yellow) - Six: Leverage Points—Places to Intervene in a System > Page 155
A balancing feedback loop is self-correcting; a reinforcing feedback loop is self-reinforcing.
Highlight (yellow) - Six: Leverage Points—Places to Intervene in a System > Page 156
Population and economic growth rates in the World model are leverage points, because slowing them gives the many balancing loops, through technology and markets and other forms of adaptation (all of which have limits and delays), time to function. It’s the same as slowing the car when you’re driving too fast, rather than calling for more responsive brakes or technical advances in steering.
Highlight (yellow) - Six: Leverage Points—Places to Intervene in a System > Page 156
If the wealthy can influence government to weaken, rather than strengthen, those measures, then the government itself shifts from a balancing structure to one that reinforces success to the successful!
Highlight (yellow) - Six: Leverage Points—Places to Intervene in a System > Page 157
Missing information flows is one of the most common causes of system malfunction.
Highlight (yellow) - Six: Leverage Points—Places to Intervene in a System > Page 157
Adding or restoring information can be a powerful intervention, usually much easier and cheaper than rebuilding physical infrastructure