---
title: Thinking in Systems [Book Summary] 
date: 2020-11-27 00:00:00
type: post
---

## Basics
* A system is a set of things— people, cells, molecules, or whatever— interconnected in such a way that they produce their own pattern of behavior over time.  
* The system, to a large extent, causes its own behavior! An outside event may unleash that behavior, but the same outside event applied to a different system is likely to produce a different result.  
* Because of feedback delays within complex systems, by the time a problem becomes apparent it may be unnecessarily difficult to solve.  
* Words and sentences must, by necessity, come only one at a time in linear, logical order. Systems happen all at once. They are connected not just in one direction, but in many directions simultaneously.  
* the basic operating unit of a system: the feedback loop.  
* The behavior of a system cannot be known just by knowing the elements of which the system is made.

## Part One: System Structure and Behavior

### How systems operate
* A system* is an interconnected set of elements that is coherently organized in a way that achieves something.
* a system must consist of three kinds of things: elements, interconnections, and a function or purpose.
* A system is more than the sum of its parts. It may exhibit adaptive, dynamic, goal- seeking, self- preserving, and sometimes evolutionary behavior.
* there is an integrity or wholeness about a system and an active set of mechanisms to maintain that integrity.
* Systems can be self- organizing, and often are self- repairing over at least some range of disruptions. They are resilient, and many of them are evolutionary.
* Can you identify parts?… and B) Do the parts affect each other?… and C) Do the parts together produce an effect that is different from the effect of each part on its own?… and perhaps D) Does the effect, the behavior over time, persist in a variety of circumstances?
* It’s easier to learn about a system’s elements than about its interconnections.
* Many of the interconnections in systems operate through the flow of information. Information holds systems together and plays a great role in determining how they operate.
* Many interconnections are flows of information— signals that go to decision points or action points within a system. These kinds of interconnections are often harder to see,
* The best way to deduce the system’s purpose is to watch for a while to see how the system behaves.
* Purposes are deduced from behavior, not from rhetoric or stated goals.
* Systems can be nested within systems. Therefore, there can be purposes within purposes.
* Keeping sub-purposes and overall system purposes in harmony is an essential function of successful systems.
* Changing elements usually has the least effect on the system.
* If you change all the players on a football team, it is still recognizably a football team.

### Stocks and Flows
* A stock is the foundation of any system. Stocks are the elements of the system that you can see, feel, count, or measure at any given time.
* A system stock is just what it sounds like: a store, a quantity, an accumulation of material or information that has built up over time.
* A stock is the memory of the history of changing flows within the system.
* Stocks change over time through the actions of a flow.
* A stock, then, is the present memory of the history of changing flows within the system.  
* A stock takes time to change, because flows take time to flow.  
* Stocks generally change slowly, even when the flows into or out of them change suddenly. Therefore, stocks act as delays or buffers or shock absorbers in systems.  
* The time lags imposed by stocks allow room to maneuver, to experiment, and to revise policies that aren’t working.  
* Stocks allow inflows and outflows to be decoupled and to be independent and temporarily out of balance with each other.  
* Systems thinkers see the world as a collection of stocks along with the mechanisms for regulating the levels in the stocks by manipulating flows.  
* How the System Runs Itself— Feedback 
* A feedback loop is formed when changes in a stock affect the flows into or out of that same stock.  
* Balancing feedback loops are goal- seeking or stability- 
* A reinforcing feedback loop enhances whatever direction of change is imposed on it.  
* Reinforcing loops are found wherever a system element has the ability to reproduce itself or to grow as a constant fraction of itself. Those elements include populations and economies.
* Reinforcing feedback loops are self- enhancing, leading to exponential growth or to runaway collapses over time. They are found whenever a stock has the capacity to reinforce or reproduce itself.
* If A causes B, is it possible that B also causes A?
* The information delivered by a feedback loop can only affect future behavior; it can’t deliver the information, and so can’t have an impact fast enough to correct behavior that drove the current feedback.
your mental model of the system needs to include all the important flows, or you will be surprised by the system’s behavior.
* A stock- maintaining balancing feedback loop must have its goal set appropriately to compensate for draining or inflowing processes that affect that stock. Otherwise, the feedback process will fall short of or exceed the target for the stock.
* Systems with similar feedback structures produce similar dynamic behaviors.


### Stocks, Flows, Loops and Physical Systems
* Economies are extremely complex systems; they are full of balancing feedback loops with delays, and they are inherently oscillatory. 
* any physical, growing system is going to run into some kind of constraint, sooner or later. That constraint will take the form of a balancing loop that in some way shifts the dominance of the reinforcing loop driving the growth behavior, either by strengthening the outflow or by weakening the inflow.
* In physical, exponentially growing systems, there must be at least one reinforcing loop driving the growth and at least one balancing loop constraining the growth, because no physical system can grow forever in a finite environment.
* Nonrenewable resources are stock- limited. The entire stock is available at once, and can be extracted at any rate (limited mainly by extraction capital). But since the stock is not renewed, the faster the extraction rate, the shorter the lifetime of the resource.
* Renewable resources are flow- limited. They can support extraction or harvest indefinitely, but only at a finite flow rate equal to their regeneration rate. If they are extracted faster than they regenerate, they may eventually be driven below a critical threshold and become, for all practical purposes, nonrenewable.
* If the feedback is fast enough to stop capital growth before the critical threshold is reached, the whole system comes smoothly into equilibrium. If the balancing feedback is slower and less effective, the system oscillates. If the balancing loop is very weak, so that capital can go on growing even as the resource is reduced below its threshold ability to regenerate itself, the resource and the industry both collapse.
* The trick, as with all the behavioral possibilities of complex systems, is to recognize what structures contain which latent behaviors, and what conditions release those behaviors— and, where possible, to arrange the structures and conditions to reduce the probability of destructive behaviors and to encourage the possibility of beneficial ones.

## Part Two: Systems and Us

### Resilient Systems
* Resilience is a measure of a system’s ability to survive and persist within a variable environment. The opposite of resilience is brittleness or rigidity.  
* Resilience arises from a rich structure of many feedback loops that can work in different ways to restore a system even after a large perturbation.  
* A set of feedback loops that can restore or rebuild feedback loops is resilience at a still higher level— meta- resilience, 
* Even higher meta- meta- resilience comes from feedback loops that can learn, create, design, and evolve ever more complex restorative structures. Systems that can do this are self- organizing, 
* Short- term oscillations, or periodic outbreaks, or long cycles of succession, climax, and collapse may in fact be the normal condition, which resilience acts to restore!  
* systems that are constant over time can be unresilient.  
* think of resilience as a plateau upon which the system can play, performing its normal functions in safety. A resilient system has a big plateau, a lot of space over which it can wander, with gentle, elastic walls that will bounce it back, if it comes near a dangerous edge. As a system loses its resilience, its plateau shrinks, and its protective walls become lower and more rigid, until the system is operating on a knife- edge,
* Systems need to be managed not only for productivity or stability, they also need to be managed for resilience— the ability to recover from perturbation, the ability to restore or repair themselves.

### Hierarchical and Self Organising Systems
* This capacity of a system to make its own structure more complex is called self- organization.
* Self- organization produces heterogeneity and unpredictability. It is likely to come up with whole new structures, whole new ways of doing things. It requires freedom and experimentation,
* conditions that encourage self- organization often can be scary for individuals and threatening to power structures. As a consequence, education systems may restrict the creative powers of children instead of stimulating those powers.
* In the process of creating new structures and increasing complexity, one thing that a self- organizing system often generates is hierarchy.
* Complex systems can evolve from simple systems only if there are stable intermediate forms.
* The resulting complex forms will naturally be hierarchic. That may explain why hierarchies are so common in the systems nature presents to us. Among all possible complex forms, hierarchies are the only ones that have had the time to evolve. 5
* In hierarchical systems relationships within each subsystem are denser and stronger than relationships between subsystems. Everything is still connected to everything else, but not equally strongly.
* Early farmers decided to come together and form cities for self- protection and for making trade more efficient.
* The original purpose of a hierarchy is always to help its originating subsystems do their jobs better.
* When a subsystem’s goals dominate at the expense of the total system’s goals, the resulting behavior is called suboptimization.
* To be a highly functional system, hierarchy must balance the welfare, freedoms, and responsibilities of the subsystems and total system— there must be enough central control to achieve coordination toward the large- system goal, and enough autonomy to keep all subsystems flourishing, functioning, and self- organizing.
 

### Systems as models and predicting behaviour
* Everything we think we know about the world is a model. Every word and every language is a model. All maps and statistics, books and databases, equations and computer programs are models. So are the ways I picture the world in my head— my mental models. None of these is or ever will be the real world.  
* our models fall far short of representing the world fully. That is why we make mistakes and why we are regularly surprised.
* It’s endlessly engrossing to take in the world as a series of events, and constantly surprising, because that way of seeing the world has almost no predictive or explanatory value.
* The structure of a system is its interlocking stocks, flows, and feedback loops.
* Structure determines what behaviors are latent in the system. A goal- seeking balancing feedback loop approaches or holds a dynamic equilibrium. A reinforcing feedback loop generates exponential growth. The two of them linked together are capable of growth, decay, or equilibrium. If they also contain delays, they may produce oscillations.
* System structure is the source of system behavior.
* Systems thinking goes back and forth constantly between structure (diagrams of stocks, flows, and feedback) and behavior (time graphs).
* behavior- based models are more useful than event- based ones, but they still have fundamental problems. First, they typically overemphasize system flows and underemphasize stocks. Economists follow the behavior of flows, because that’s where the interesting variations and most rapid changes in systems show up.
* We are too fascinated by the events they generate. We pay too little attention to their history. And we are insufficiently skilled at seeing in their history clues to the structures from which behavior and events flow.

### System Boundaries
* systems rarely have real boundaries.
* There are only boundaries of word, thought, perception, and social agreement— artificial, mental- model boundaries.
* When you draw boundaries too narrowly, the system surprises you. For example, if you try to deal with urban traffic problems without thinking about settlement patterns, you build highways, which attract housing developments along their whole length. Those households, in turn, put more cars on the highways, which then become just as clogged as before.
* There are no separate systems. The world is a continuum. Where to draw a boundary around a system depends on the purpose of the discussion— the questions we want to ask.
* We get attached to the boundaries our minds happen to be accustomed to.
* boundaries are of our own making, and that they can and should be reconsidered for each new discussion, problem, or purpose.
* Economics evolved in a time when labor and capital were the most common limiting factors to production
* growth itself depletes or enhances limits and
* therefore changes what is limiting.
* To shift attention from the abundant factors to the next potential limiting factor is to gain real understanding of, and control over, the growth process
* For any physical entity in a finite environment, perpetual growth is impossible. Ultimately, the choice is not to grow forever but to decide what limits to live within.
* Just as the appropriate boundaries to draw around one’s picture of a system depend on the purpose of the discussion, so do the important delays

### Bounded Rationality
* Delays determine how fast systems can react, how accurately they hit their targets, and how timely is the information passed around a system
* When there are long delays in feedback loops, some sort of foresight is essential. To act only when a problem becomes obvious is to miss an important opportunity to solve the problem.
* Bounded rationality means that people make quite reasonable decisions based on the information they have. But they don’t have perfect information, especially about more distant parts of the system
* We do our best to further our own nearby interests in a rational way, but we can take into account only what we know
* We often don’t foresee (or choose to ignore) the impacts of our actions on the whole system. So instead of finding a long-term optimum, we discover within our limited purview a choice we can live with for now, and we stick to it, changing our behavior only when forced to.
* Change comes first from stepping outside the limited information that can be seen from any single place in the system and getting an overview
* The bounded rationality of each actor in a system may not lead to decisions that further the welfare of the system as a whole.
* What makes a difference is redesigning the system to improve the information, incentives, disincentives, goals, stresses, and constraints that have an effect on specific actors.

### Policy Resistance
* Policy resistance comes from the bounded rationalities of the actors in a system, each with his or her (or “its” in the case of an institution) own goals.
* Each actor monitors the state of the system with regard to some important variable—income or prices or housing or drugs or investment—and compares that state with his, her, or its goal. If there is a discrepancy, each actor does something to correct the situation.
* The most effective way of dealing with policy resistance is to find a way of aligning the various goals of the subsystems, usually by providing an overarching goal that allows all actors to break out of their bounded rationality
* Harmonization of goals in a system is not always possible, but it’s an option worth looking for. It can be found only by letting go of more narrow goals and considering the long-term welfare of the entire system.
* When various actors try to pull a system stock toward various goals, the result can be policy resistance. Any new policy, especially if it’s effective, just pulls the stock farther from the goals of other actors and produces additional resistance, with a result that no one likes, but that everyone expends considerable effort in maintaining.
* The tragedy of the commons arises from missing (or too long delayed) feedback from the resource to the growth of the users of that resource.
* If you think that the reasoning of an exploiter of the commons is hard to understand, ask yourself how willing you are to carpool in order to reduce air pollution
* The structure of a commons system makes selfish behavior much more convenient and profitable than behavior that is responsible to the whole community and to the future.
* When there is a commonly shared resource, every user benefits directly from its use, but shares the costs of its abuse with everyone else. Therefore, there is very weak feedback from the condition of the resource to the decisions of the resource users. The consequence is overuse of the resource, eroding it until it becomes unavailable to anyone.
* Educate and exhort the users, so they understand the consequences of abusing the resource. And also restore or strengthen the missing feedback link, either by privatizing the resource so each user feels the direct consequences of its abuse or (since many resources cannot be privatized) by regulating the access of all users to the resource.

## Part Three: Creating Change—in Systems and in Our Philosophy

* Leverage points frequently are not intuitive. Or if they are, we too often use them backward, systematically worsening whatever problems we are trying to solve.
* A balancing feedback loop is self-correcting; a reinforcing feedback loop is self-reinforcing.
* Population and economic growth rates in the World model are leverage points, because slowing them gives the many balancing loops, through technology and markets and other forms of adaptation (all of which have limits and delays), time to function. It’s the same as slowing the car when you’re driving too fast, rather than calling for more responsive brakes or technical advances in steering.
* If the wealthy can influence government to weaken, rather than strengthen, those measures, then the government itself shifts from a balancing structure to one that reinforces success to the successful!
* Missing information flows is one of the most common causes of system malfunction.
* Adding or restoring information can be a powerful intervention, usually much easier and cheaper than rebuilding physical infrastructure
